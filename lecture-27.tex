% !TEX spellcheck = en_US
% !TEX spellcheck = LaTeX
\documentclass[a4paper,10pt,english]{article}
\input{header}
\title{Lecture 27: Random Walks}
\author{}

\begin{document}
\maketitle
\section{Introduction}
Let $X = \{X_n: n \in \N\}$ be a sequence of \textit{iid} random variables with $\E|X_n| < \infty$. 
Let $S_0 = 0$ and $S_n = \sum_{i=1}^nX_i$. 
Then the sequence $S = \{S_n: n \in \N_0\}$ is called a \textit{random walk process}. 
\begin{shaded*}
\begin{exmp}[Simple random walk] 
Let $X_i \in \{-1,1\}$ and $\Pr\{X_i = 1\} = p$, then random walk $S$ is called a simple random walk. 
\end{exmp}
\begin{exmp}
Stock prices each day can be modeled by a random walk. 
\end{exmp}
\end{shaded*}
Random walks are generalizations of renewal processes. 
If $X$ was a sequence of non-negative random variables indicating inter-renewal times, 
then $S_n$ is the instant of the $n$th renewal event. 

\section{Duality in random walks}
\begin{lem}[Duality principle] 
For any finite $n \in \N$, the joint distributions of finite sequence $(X_1,X_2,\cdots,X_n)$ and the reversed sequence $(X_n, X_{n-1},\cdots, X_1)$ are identical.
\end{lem}
\begin{proof}
Since $X$ is a sequence of \textit{iid} random variables, it is exchangeable. 
The reversed sequence is $(X_{\pi(1)}, \dots, X_{\pi(n)})$ where $\pi: [n] \to [n]$ is permutation with $\pi(i) = n-i+1$. 
\end{proof}
 \begin{cor} 
 Distribution of $S_k$ and $S_n - S_{n-k}$ are identical for any $k \in [n]$.  
 \end{cor}
 \begin{proof} 
 Using duality principle, we can write the following equality for any $x \in \R, k \in [n]$
 \eq{
 \Pr\{S_k \leq x\} &= \Pr\{\sum_{i=1}^{k}X_i \leq x\} = \Pr\{\sum_{i=1}^{k}X_{n-i+1} \leq x\} =  \Pr\{\sum_{i=n-k+1}^{n}X_{i} \leq x\} = \Pr\{S_n - S_{n-k} \leq x\}.
 }
 \end{proof}
%The first result we shall show that if $\E[X_1] >0 $ then the random walk will become positive in finite steps. 
\begin{prop}
Suppose $\{X_n: n \in \N\}$ is a sequence of iid random variables with positive mean. 
Let $S_n = \sum_{k=1}^n X_i$ be a random walk with step size $X_n$. If 
%\begin{align*}
$N = \min \{n \in \N : S_n > 0\}$, 
%\end{align*}
then $\E N < \infty$.
\end{prop}
\begin{proof} 
%We can write the mean of stopping time $N$ as 
%\begin{align*} 
%\E N &= \sum_{n \in \N_0} \Pr\{N > n\} = \sum_{n \in \N_0} \Pr\{S_n \leq S_{n-i}, i \in [n]\}.
%\end{align*}
Consider a discrete process $\{T_k \in \N_0: k \in \N_0\}$, where $T_0 = 0$ and for each $k \in \N_0$
\eq{
T_{k+1} &= \inf\{n > T_{k} : S_n \leq S_{N_{k}}\} = N_{k} + \inf\{ n \in \N: S_{N_{k}+n} \leq S_{N_{k}}\}.
}
Since for any finite $n \in \N$, the distribution of $(X_1, \dots, X_n)$ is identical to that of $(X_{T_{k}+1}, \dots, X_{T_{k}+n})$, 
and 
\eq{
T_{k+1} - T_{k} &= \inf\{n \in \N: \sum_{i=1}^{n}X_{T_{k}+i} \leq 0\}, 
}
we observe that $T_{k} - T_{k-1}$ are \textit{iid} for each $k \in \N$, with complementary distribution 
\eq{
\bar{F}(m) &= \Pr\{T_{k+1} - T_k > m\} = \Pr\{S_1 > 0, S_2 > 0, \dots, S_m > 0\}. 
}
Therefore, $\{T_k: k \in \N_0\}$ is a renewal process and at each renewal instant $\{T_k = n\}$, 
\eq{
S_{n} \leq S_{n-1}, S_n \leq S_{n-2}, \dots, S_n \leq 0.
}
Hence, $T_k$ denotes the $k$th renewal instant corresponding to the random walk $S_n$ hitting $k$th low. 
We can define the inverse counting process $\{N_n \in \N_0: n \in \N_0\}$ for this renewal process as 
\begin{xalignat*}{3}
&N_n = \sum_{j = 1}^{n}1_{\{T_j \leq n\}},&&\text{ or } \{N_n \geq k\} = \{T_k \leq n\}. 
\end{xalignat*}
From definition of stopping time $N$ and duality principle, we can write 
\eq{
\Pr\{N > n\} &= \Pr\{S_1 \leq 0, \dots, S_n \leq 0\} =  \Pr\{S_n \leq S_{n-1}, \dots, S_n \leq 0\}.
}
The event of renewal process hitting a new low at $n$ is same as some renewal occurring at time $n$. 
That is,
%Therefore, %we can write 
\eq{
\sum_{n \in \N}1_{\{S_n \leq S_{n-1}, S_{n} \leq S_{n-2}, \dots, S_{n} \leq S_0 \}} &= \sum_{n \in \N}\sum_{k=1}^n1_{\{T_k = n\}} = \sum_{k \in \N}\sum_{n \geq k}1_{\{T_k = n\}} = \sum_{k \in \N}1_{\{T_k \leq \infty \}} = N_{\infty}. 
}
Therefore, we can write the mean of stopping time $N$ as 
\eq{
\E N &= 1 + \sum_{n \in \N}\Pr\{N > n\} = 1 + \sum_{n \in \N}\sum_{k=1}^n\Pr\{T_k = n\} =1 + \sum_{k\in \N}\sum_{n \geq k}\Pr\{T_k = n\} = 1 + \E N_{\infty}. 
}
%Hence, $n$ is a renewal instant after $0$ if $\{S_n \leq S_i: i \in [n]\}$. Hence, we have
%\begin{align*}
%\E N &= \sum_{n\in \N_0}\Pr\{\text{renewal happens at time } n\} = \sum_{n \in \N_0}\Pr\{\text{inter-renewal length} \geq n\}\\
%&= 1 + \E[\text{Number of renewals that occur}]
%\end{align*}
%
%Now let us count a renewal at time $n$ when $S_n \leq S_{n-1},S_{n} \leq S_{n-2}, \cdots, S_n \leq 0$. Then we get
%\begin{flalign}
%E[N] &= \sum_{n=0}^\infty P[\mbox{renewal happens at time n}]\\
%&= 1 + E[\mbox{No of renewals that occur}]
%\end{flalign}
Since $\E X_1 > 0$, it follows from strong law of large numbers that $S_n \to \infty$. 
Hence, the expected number of renewals that occur is finite. 
Thus $\E N < \infty$.
\end{proof}
%\begin{defn}
%\end{defn}
The number of distinct values of $(S_0,\cdots, S_n)$ is called \textbf{range}, denoted by $R_n$
We define by stopping time $T_k$, first return of random walk to $k$
\eq{
T_k &= \inf \{n \in \N: S_n = k\}.
}
\begin{prop}
For a simple random walk, 
\eq{
\lim_{n \in \N} \frac{\E R_n}{n} = \Pr\{T_0 > \infty \}.
}
\end{prop}
\begin{proof}
We can define indicator function for $S_k$ being a distinct number from $S_1, \dots, S_{k-1}$, as
\eq{
I_k &=1_{\{S_k \neq S_{k-1}, \dots, S_{k} \neq S_1 \}}.
}
Then, we can write range $R_n$ in terms of indicator $I_k$ as 
\begin{align*}R_n = 1 + \sum_{k=1}^nI_k\end{align*}
%We define a stopping time for random walk to hit zero as $T = \{n > 0: S_n = 0\}$. 
%Then, 
%\eq{
%\lim_{k \in \N} \Pr\{T > k\} = \Pr\{S_n \neq 0, \forall n \in \N\}.
%} 
Further, using the duality principle, we can write
\eq{
\E R_n &= 1 + \sum_{k=1}^n \Pr\{S_1\neq 0, \dots, S_k \neq 0\} 
%&= 1 + \sum_{k=1}^n P[S_1 \neq 0, S_2 \neq 0, \cdots, S_k \neq 0] \\
= \sum_{k=0}^n \Pr\{T_0 > k\}
}
%Where $T$ is the first time the RW returns to 0. 
Result follows by dividing both sides by $n$ and taking limits.
\end{proof}

%\begin{exmp*}
\subsection{Simple random walk}
\begin{thm}[range]
For a simple random walk with $\Pr\{X_1 = 1\} = p$, the following holds
\begin{align*}
\lim_{n \in \N}\frac{\E R_n }{n} &= 
	\begin{cases}
2p - 1, & p > \frac{1}{2}\\
2(1-p)-1, & p \leq \frac{1}{2}.
	\end{cases}
\end{align*}
\end{thm}
\begin{proof}
%Consider the simple random walk with $\Pr\{X_i = 1\} = p$. 
When $p=\frac{1}{2}$, this random walk is recurrent and thus
\begin{align*}
\Pr\{T_0 > \infty\} = 0 = \lim_{n \in \N} \frac{\E R_n}{n}.
\end{align*}
For$p > \frac{1}{2}$, let $\alpha = \Pr\{ T_0 < \infty |X_1 = 1\}$. 
Since $\E X > 0$, we know that $S_n \to \infty$ and hence $\Pr\{T_0  < \infty |X_1 = -1\} = 1$. 
We can write unconditioned probability of return of random walk to $0$ as 
\begin{align*}
\Pr\{T_0 < \infty\} = \alpha p+ 1-p.
\end{align*}
Conditioning on $X_2$ and from strong law of large numbers, we yield
\begin{align*}
\alpha &= \Pr\{T_0 < \infty |X_1 = 1\} = p\Pr\{T_0 < \infty | S_2  = 2\}  + (1-p).
%\Pr\{S_n = 0 \text{ for some }n| S_2 = 0\}\\
\end{align*}
From Markov property and homogeneity of random walk process, it follows that 
\begin{align*}
\Pr\{T_0 < \infty | S_2  = 2\} &= \Pr\{T_0 < \infty | S_{T_1} = 1, T_1 < \infty \}\Pr\{T_1 < \infty | S_2 = 2\} = \alpha^2.
\end{align*}
We conclude $\alpha = \alpha^2 p + 1-p$, and since $\alpha < 1$ due to transience, we get $\alpha = \frac{1-p}{p}$, and hence the result follows. We can show similarly for the case when $p < 1/2$.
%. Thus for $p > 1/2$,
%\begin{align*}\lim_{n \in \N}\frac{\E[R_n]}{n} = 2p-1.\end{align*}
%Similarly, we can show for $p \leq 1/2$, we have
%\begin{align*}\lim_{n \in \N}\frac{\E[R_n]}{n} = 2(1-p)-1.\end{align*}
\end{proof}

\begin{prop}
In the symmetric random walk, the expected number of visits to state $k$ before returning to origin is equal to $1$ for all $k \neq 0$.
\end{prop}
\begin{proof}
Fix a state $k > 0$, and let $T_k$ be the hitting time to state $k$ for the random walk $S_n$. 
Further, let $Y$ denote the number of visits to state $k$ before the first return to origin. 
Using an indicator function  $I_n = 1_{\{S_k = n, N_0 > n\}}$ for the return to state $k$ after $n$th step, before hitting origin, 
we can write  
\begin{align*}
Y = \sum_{n \in \N} I_n.
\end{align*}

Thus, using duality principle and recurrence of symmetric random walk, we can write
\begin{align*}
\E Y &= \sum_{n \in \N} \Pr\{S_1 > 0, \dots, S_n > 0, S_n = k\}= \sum_{n \in \N}\Pr\{S_n - S_{n-1} > 0,\dots, S_n > 0, S_n = k\}\\
%&= \sum_{n \in \N} \Pr\{S_n > S_{n-i}, i \in [n], S_n=k\}\\
&= \sum_{n \in \N} \Pr\{N_k = n\} = \Pr\{S_n = k \text{ for some }n\} = 1.
\end{align*}
\end{proof}
%\end{exmp*}

\subsection{ GI/GI/1 Queueing Model}
Consider a $GI/GI/1$ queue. Customers arrive in accordance with a renewal process having an arbitrary interarrival distribution  $F$, and the service distribution is $G$. %Let the interarrival times be $X_1,~X_2 \hdots $ and let the service times be $Y_1,~Y_2 \hdots$ and let $D_n$ denote the delay in queue of the $n^\text{th}$ arrival. 
\begin{prop}
\label{prop_gigi1}
Let $D_n$ be the delay in the queue of the $n^\text{th}$ customer in a GI/GI/1 queue with independent inter-arrival times $X_n$ and service times $Y_n$. 
Let $S_n$ be a random walk with \textit{iid} steps $U_n = Y_n - X_{n+1}$ for all $n \in \N$. 
%\begin{equation*}
%S_n =\sum_{i=1}^{n}Y_n-X_{n+1},~n \in \N.
%\end{equation*}
Then, we can write
\begin{align}
\label{GIGI1_prop_eqn}
\Pr\{D_{n+1} \geq c\} = \Pr\{S_j \geq c, \text{ for some }j \in [n]\}.
\end{align}
\end{prop}
\begin{proof}
The following recursion for $D_n$ is easy to verify
\begin{align*}
 D_{n+1} &= (D_n+Y_n-X_{n+1})1_{\{D_n+Y_n - X_{n+1} \geq 0\}} = \max\{0,D_n+U_n\}.
\end{align*}
%Using definition $U_n := Y_n-X_{n+1}$ for all $n \in \N$, we can re-write this as
%\begin{equation*}
%D_{n+1}=\max\{0,D_n+U_n\},~ n \in \N.
%\end{equation*}
Iterating the above relation with $D_1 = 0$ yields
\begin{align*}
D_{n+1}&= \max\{0,U_n+\max\{0,D_{n-1}+U_{n-1}\}\}=\max\{0,U_n,U_n+U_{n-1}+D_{n-1}\}.
\end{align*}
For the random walk $S_n$ with steps $U_n$, we can write delay in terms of random walk $S_n$ as
\begin{align*}
D_{n+1} &=\max\{0,S_n-S_{n-1},S_n-S_{n-2}, \ldots, S_n - S_0\}.
\end{align*}
Using the duality principle, we can rewrite the following equality for delay in distribution  
%where in the last step we have used the fact that $D_1=0$. Hence, for $c>0$,
\begin{align*}
D_{n+1} &=\max\{0,S_1,S_2, \ldots , S_n\}.
\end{align*}
%where the last equality follows from duality. Thus the following proposition holds.
\end{proof}
\begin{cor} If $\E U_n \geq 0$, then for all $c$, we have 
%\begin{align*}
$\Pr\{D_{\infty} \geq c\} \triangleq \lim_{n \in \N}\Pr\{D_{n} \geq c\} = 1$.
%\end{align*}
\end{cor}
\begin{proof}
It follows from Proposition~\ref{prop_gigi1} that $\Pr\{D_{n+1} \geq c\}$ is nondecreasing in $n$. 
Hence, by MCT the limit exists and is denoted by $\Pr\{D_{\infty} \geq c\}=\lim_{n \in \N}\Pr\{D_{n} \geq c\}$. 
Therefore, by continuity of probability, we have from~\eqref{GIGI1_prop_eqn}, that
\begin{align}
\label{random_walk_gigi1}
\Pr\{D_{\infty} \geq c\} &= \Pr\{S_n \geq c \text{ for some }n\}.
\end{align}
If $\E U_n = \E Y_n - \E X_{n+1}$ is positive, then by strong law of large numbers the random walk $S_n$ will converge to positive infinity with probability 1. 
The above will also be true when $E[U_n] = 0$, then the random walk is recurrent.
%Hence,
%\begin{equation*}
%Pr(D_{\infty} \geq c) =1,~ \forall c ~\text{if}~ E[Y]>E[X].
%\end{equation*}
\end{proof}
\begin{rem} Hence, we get that $\E Y_n< \E X_{n+1}$ implies the existence of a stationary distribution.
\end{rem}

\begin{prop}[Spitzer's Identity] Let $M_n=\max\{0,S_1,S_2, \ldots, S_n\}$ for $n \in \N$, then %We have the following proposition.
\begin{align*}
\E M_n &= \sum_{k=1}^{n} \frac{1}{k} \E S_k^+.
\end{align*}
\end{prop}
\begin{proof}
We can decompose $M_n$ as 
\begin{equation*}
M_n=1_{\{S_n>0\}}M_n+1_{\{S_n \leq 0\}}M_n.
\end{equation*}
We can rewrite first term in decomposition as, 
\begin{equation*}
1_{\{S_n>0\}}M_n= 1_{\{S_n>0\}}\max_{i \in [n]}S_i = 1_{\{S_n>0\}}(X_1+\max\{0,S_2 - S_1,\ldots, S_n - S_1\})
\end{equation*}
%By exchangeability, the joint distribution of $(X_1, \ldots, X_n)$ and $(X_n,X_1, \ldots, X_{n-1})$ are same.
Hence, taking expectation and using exchangeability, we get 
\begin{align*}
%\label{sptiz_1}
\E[M_n1_{\{S_n>0\}}] &= %\E 1_{\{S_n>0\}} X_1 + \E 1_{\{S_n>0\}} \max\{0,S_1,\ldots, S_{n-1}\} =   
\E[X_11_{\{S_n>0\}}]  + \E[M_{n-1}1_{\{S_n>0\}}].
\end{align*}
%By exchangeability, the joint distribution of $(X_1, \ldots, X_n)$ and $(X_n,X_1, \ldots, X_{n-1})$ are the same. 
%\begin{equation}
%\label{sptiz_2}
% E[ 1_{\{S_n>0\}} \max\{0,X_2,\hdots X_2+\hdots +X_n\}]=E[1_{\{S_n >0\}}M_{n-1}].
%\end{equation}
Since $X_i,S_n$ has the same joint distribution for all $i$,
\begin{align*}
\E S_n^+ &= \E[S_n1_{\{S_n>0\}}]=\E\sum_{i=1}^{n}X_i 1_{\{S_n>0\}}]=n\E[X_11_{\{S_n>0\}}].
\end{align*}
%Hence,
%\begin{equation}
%\label{sptiz_3}
%\E[X_11_{\{S_n>0\}}]=\frac{1}{n}\E[S_n 1_{\{S_n>0\}}] =\frac{1}{n}\E[S_n^+].
%\end{equation}
%From equations \ref{sptiz_1}, ~\ref{sptiz_2}, ~ \ref{sptiz_3}, we have that
Therefore, it follows that
\begin{align*}
\E[1_{\{S_n>0\}}M_n] &=\E[1_{\{S_n>0\}}M_{n-1}]+\frac{1}{n}\E[S_n^+].
\end{align*}
Also, $S_n \leq 0$ implies that $M_n=M_{n-1}$, it follows that
\begin{align*}
1_{\{S_n\leq 0\}}M_n=1_{\{S_n\leq 0\}}M_{n-1}.
\end{align*}
Thus, we obtain the following recursion,
\begin{align*}
\E[M_n]&=\E[M_{n-1}]+\frac{1}{n}\E[S_n^+].
\end{align*}
Result follow from the fact that $M_1 =S_1^+$.
%Upon recursion, we get
% \begin{equation*}
%\E[M_n]= \sum_{k=2}^{n} \frac{1}{k} \E[S_k^+]+\E[M_1].
%\end{equation*}
\end{proof}
\begin{rem} Since $D_{n+1} = M_n$, we have 
%From Proposition \ref{prop_gigi1}, with $M_n=\max\{0,S_1,\hdots S_n\}$
% \begin{equation*}
%Pr(D_{n+1} \geq c) = Pr(M_n \geq c).
%\end{equation*}
%Hence,
 %\begin{align*}
$\E[D_{n+1}] =\E[M_n] = \sum_{k=1}^{n} \frac{1}{k}E[S_k^+]$.
%\end{align*}
%From Spitzer's identity we see that
% \begin{equation*}
%E[D_{n+1}]= \sum_{k=1}^{n} \frac{1}{k}E[S_k^+].
%\end{equation*}
\end{rem}
\section{Martingales for Random Walks}
%Let
%\begin{align*}S_n = \sum_{k=1}^n X_k \quad n \geq 1\end{align*}
%denote a random walk. Then we have the following results.
\begin{prop}
A random walk $S_n$ with step size $X_n \in [-M,M]\cap \Z$ for some finite $M$ is a recurrent DTMC iff $\E X = 0$.
\end{prop}
\begin{proof}
If $\E X \neq 0$, the random walk is clearly transient since, it will diverge to $\pm \infty$ depending on the sign of $\E X$. 
Conversely, if $\E X =0$, then $S_n$ is a martingale. 
Assume that the process starts in state $i$. 
We define
\meq{3}{
&A = \{-M, -M+1,\cdots,-2,-1\}, &&A_j =\{j+1, \dots, j+M\}, ~j > i.
}
%\begin{align*}A_j = \{j, j+1,\cdots,j+M\}\end{align*}
Let $N$ denote the hitting time to $A$ or $A_j$ by random walk $S_n$. 
Since $N$ is a stopping time and $S_{N\wedge n} \leq |M|+j$, by optional stopping theorem, we have
\begin{align*}
\E_i[S_N] =\E_i[S_0] = i.
\end{align*}
Thus we have
\begin{align*}
i &= \E_i[S_N] %= \E_i[S_N|S_N \in A]\Pr\{S_N \in A\} + \E_i[S_N|S_N \in A_i]\Pr\{S_N \in A_j]\\
\geq -M\P_i\{S_N \in A\} + j(1-\P_i\{S_N \in A\}). 
\end{align*}
Rearranging this, we get a bound on probability of random walk $S_n$ hitting $A$ over $A_j$ as 
\begin{align*}
\P_i\{S_n \in A \text{ for some } n\} \geq \P_i\{S_N \in A\} \geq \frac{j-i}{j+M}.
\end{align*}
%Thus we have 
%\begin{align*}P[\mbox{process ever enters }A] \geq P[S_N \in A] \geq \frac{j-i}{j+M}\end{align*}
Taking limit $j \to \infty$, we see that for any $i \geq 0$, we have 
%\begin{align*}
$\P_i\{S_n \in A \text{ for some }n \} = 1$.
%\end{align*}
Similarly, taking $B = \{1,2,\cdots, M\}$, we can show that for any $i \geq 0$, 
%\begin{align*}
$\P_i\{S_n \in B \text{ for some }n \} = 1.$
%\end{align*}
Result follows from combining the above two arguments to see that for any $i \geq 0$,
\begin{align*}
\P_i\{S_n \in A\cup B \text{ for some } n\} = 1.
\end{align*}
\end{proof}
\begin{prop} 
Consider a random walk $S_n$ with mean step size $\E[X] \neq 0$. 
For $A,B > 0$, let $P_A$ denote the probability that the walk hits a value greater than $A$ before it hits a value less than $-B$. 
Then, for $\theta \neq 0$ such that $\E e^{\theta X_1} = 1$, we have
\begin{align*}
P_A \approx \frac{1-e^{-\theta B}}{e^{\theta A}-e^{-\theta B}}.
\end{align*}
Approximation is an equality when step size is unity and $A$ and $B$ are integer valued.
\end{prop}
\begin{proof}
For any $A,B > 0$, we can define stopping times
\meq{3}{
&T_A = \inf\{n \in \N: S_n \geq a\},&&T_{-B} = \inf\{n \in \N: S_n \leq -B\}.
}
We are interested in computing the probability 
\eq{
P_A &= \Pr\{T_A < T_{-B}\}.
}
%we wish to compute the probability $P_A$ that the walk hits at least $A$ before it hits a value $\leq -B$. %Let $\theta \neq 0$ s.t
%\begin{align*}
%\E[e^{\theta X}] = 1. 
%\end{align*}
Now let $Z_n = e^{\theta S_n}$. We can see that $Z_n$ is a martingale with mean 1. 
Define a stopping time $N = T_A \wedge T_{-B}$. 
%\begin{align*}
%N = \min \{S_n \geq A \mbox{ or } S_n \leq -B\}.
%\end{align*}
From Doob's Theorem, $E[e^{S_N}] = 1$. 
Thus we get
\eq{
1 = \E[e^{\theta S_N}|S_N \geq A]P_A + \E[e^{\theta S_N}|S_N \leq -B](1-P_A).
}
We can obtain an approximation for $P_A$ by neglecting the overshoots past $A$ or $-B$. 
Thus we get
\meq{3}{
&\E[e^{\theta S_N}|S_N\geq A] \approx e^{\theta A},&&E[e^{\theta S_N}|S_N\leq -B] \approx e^{-\theta B}.
}
The result follows. 
\end{proof}
\begin{cor} 
Show that 
\eq{
\E N \approx \frac{AP_A - B(1-P_A)}{\E X}.
}
\end{cor}
\begin{shaded*}
\begin{exmp}[Gambler's Ruin] 
Consider a simple random walk with $\Pr\{X_i = 1\} = p$.  
It is easy to see that $\E\left[(q/p)^X\right] = 1$ and thus taking $e^\theta = q/p$, we have $\E e^{\theta X} = 1$.  
If $A$ and $B$ are integers, then there is no overshoot and hence, our approximations are exact. Thus
\eq{
P_A = \frac{(q/p)^B - 1}{(q/p)^{A+B} -1}.
}
Suppose $\E X < 0$ and we wish to know if the random walk ever crosses $A$. 
Then
\eq{
1 &= \E[e^{\theta S_N}|S_N\geq A]\Pr\{T_A < T_{-B}\}+ \E[e^{\theta S_N}|S_N\leq -B]\Pr\{T_{-B} < T_A\}.
}
We choose  $\theta$ such that $\E e^{\theta X} = 1$. 
Since $\E X<0$, it implies $\theta > 0$. 
Hence, we have
\eq{
1 \geq e^{\theta A}\Pr\{T_A < T_{-B}\}.
}
Taking $B$ to $\infty$ yields
\eq{
\Pr\{S_n \geq A \text{ for some } n \in \N\} = \Pr\{T_A < \infty \} \leq e^{-\theta A}.
}

\end{exmp}
\end{shaded*}

\section{Application to G/G/1 Queues and Ruin}
\subsection{The G/G/1 Queue}
For the G/G/1 queue, the limiting distribution of delay is
\begin{align*}P[D_\infty \geq A] = P[S_n \geq A \mbox{ for some } n]\end{align*}
where 
\begin{align*}S_n = \sum_{k=1}^n U_k, \quad U_k = Y_k-X_{k+1} \end{align*}
Here $Y_i$ is the service time of the ith customer and $X_i$ is the interarrival duration between customer $i-1$ and customer $i$.
Thus when $E[U] = E[Y] - E[X] < 0$, letting $\theta > 0$ such that
\begin{align*}E[e^{\theta U}] = E[e^{\theta(Y-X)}] = 1\end{align*}
We get
\begin{align*}P[D_\infty \geq A] \leq e^{-\theta A}\end{align*} 

Now the exact distribution of $D_\infty$ can be calculated when services are exponential. Hence assume $Y_i \sim exp(\mu)$. Once again,
\begin{flalign*}
1 &= E[e^{\theta S_N}|S_N\geq A]P[S_n\mbox{ crossed $A$ before $-B$}] \\
&+ E[e^{\theta S_N}|S_N\leq -B]P[S_n\mbox{ crossed $-B$ before $A$}]
\end{flalign*}
Let us compute $E[e^{\theta S_N}|S_N \geq A]$ first. Let us condition this on $N=n$ and $X_{n+1} - \sum_{i=1}^{n-1} (Y_i - X_{i+1}) = c$. By the memoryless property, the conditional distribution of $Y_n$ given $Y_n > c+A$ is just $c+A$ plus an exponential with rate $\mu$. Thus we get
\begin{flalign*}
E[e^{\theta S_N}|S_N \geq A] &= E[e^{\theta(A+Y)}] \\
&=\frac{\mu e^{\theta A}}{\mu - \theta}
\end{flalign*}
Now substituting back, we get
\begin{flalign*}
1 &= \frac{\mu e^{\theta A}}{\mu - \theta}P[S_n\mbox{ crossed $A$ before $-B$}] \\
&+ E[e^{\theta S_N}|S_N\leq -B]P[S_n\mbox{ crossed $-B$ before $A$}]
\end{flalign*}
Now as $\theta > 0$, let $B\to \infty$ to get
\begin{align*}1 = \frac{\mu e^{\theta A}}{\mu - \theta} P[S_n \mbox{ ever crosses }A]\end{align*}
And hence
\begin{align*}P[D_\infty \geq A] = \frac{\mu - \theta}{\mu}e^{-\theta A}\end{align*}

\subsection{A Ruin Problem}
Suppose claims made to an insurance company follow a renewal process with iid interarrival times $\{X_i\}$. Let the values of the claims also be iid and independent of the renewal process $N(t)$ of their occurence. Let $Y_i$ be the ith claim value. Thus the total value of claims till time $t$ is $\sum_{k=1}^{N(t)}Y_i$. Now let us suppose the insurance company receives money at constant rate $c$ per unit time, $c>0$. We wish to compute the probability of the insurance company, starting with capital $A$, will eventually be wiped out or \textbf{ruined}. Thus we require
\begin{align*}p = P\left\{ \sum_{k=1}^{N(t)}Y_i > ct + A \mbox{ for some } t\geq 0\right\}\end{align*}
As an assignment, show that the company will be ruined if $E[Y] \geq cE[X]$. So let us assume that $E[Y] < cE[X]$. Also the ruin occurs when a claim is made. After the $n$th claim, the company's fortune is
\begin{align*}A + c\sum_{k=1}^n X_k -\sum_{k=1}^n Y_k \end{align*}
Letting $S_n = \sum_{k=1}^n Y_i - cX_i$ and $p(A) = P[S_n > A \mbox{ for some }n]$. As $S_n$ is a random walk, we see that 
\begin{align*}p(A) = P[D_\infty > A]\end{align*}

Now the results from the G/G/1 queue apply.

\section{Blackwell Theorem on the Line}
Let $S_n$ denote a random walk where $0<\mu=E[X] < \infty$. Let 
\begin{align*}U(t)=\#\{n: S_n \leq t\} = \sum_{n=1}^\infty I_n\end{align*}
Where $I_n=1$ if $S_n \leq t$ and zero else. Observe that if $X_n$ are nonnegative, then $U(t) = N(t)$. Let $u(t) = E[U(t)]$. Now we prove an analog of Blackwell Renewal Theorem. 

\begin{thm}
\textbf{(Blackwell renewal theorem)} If $\mu > 0$ and $X_i$ are not lattice, then
\begin{align*}u(t+a) - u(t) \to a/\mu \quad t\to \infty \quad \mbox{for }a>0\end{align*}
\end{thm}
Let us define a few concepts. We say an \textbf{ascending ladder variable of ladder height $S_n$} occurs at time $n$ when
\begin{align*}S_n > \max(S_0,S_1,\cdots, S_{n-1})\end{align*}
where $S_0 = 0$. We may deduce that since $X_i$ are iid random variables, then the random variables $(N_i,S_{N_i}-S_{N_{i-1}})$ are iid; where $N_i$ denotes the time between the $(i-1)$th and ith random variable. We may analogously define descending ladder variables. Now let $p(p_*)$ denote the probability of ever achieving an ascending/descending ladder variable.
\begin{align*}p = P\{S_n > 0 \mbox{ for some }n\},\quad p_* = P\{S_n < 0 \mbox{ for some }n\}\end{align*}
At each ascension/descension there is a probability $p$ (resp $p_*$) of achieving another one. Hence the number of ascensions/descensions is geometrically distributed. The number of ascending ladder variables (ascensions) will have finite mean iff $p < 1$. Now as $E[X] > 0$, by SLLN, we deduce that $w.p.1$, there will be infinitely many ascending ladder variables but finitely many descending ones. That is $p =1$ and $p_* < 1$.

\begin{proof}
The successive ascending ladder heights are a renewal process. Let $Y(t)$ be the excess time. Now given the value of $Y(t)$, the distribution of $U(t+a) - U(t)$ is independent of $t$. (Why?). Hence let us denote
\begin{align*}E[U(t+a) - U(t)|Y(t)] = g(Y(t))\end{align*}
for some function $g$. Now taking expectations yields
\begin{align*}u(t+a) - u(t) = E[g(Y(t))]\end{align*}

Now since $Y(t) \to^d Y_\infty$ where $Y_\infty$ has the equilibrium distribution, we have $E[g(Y(t))] \to E[g(Y_\infty)]$. The result would be true if we show $g$ is continuous and bounded. We leave that as an exercise. For now, we deduce that the limit exists. Let
\begin{align*}h(a) = \lim_{t \to \infty}u(t+a) - u(t)\end{align*}
This also implies $h(a+b) = h(a) + h(b)$. Thus for some constant $c$, 
\begin{align*}h(a) = ca\end{align*}

Now to get $c$, let $N_t$ denote the first $n$ for which $S_n > t$. If $X_i$ are upper bounded by $M$, then
\begin{align*}t < \sum_{i=1}^{N_t} X_i \leq t+M\end{align*}
Taking expectations, and using Wald's Lemma, yields
\begin{align*}t < E[N_t]\mu \leq t+M\end{align*}
Thus 
\begin{align*}\frac{E[N_t]}{t} \to \frac{1}{\mu}\end{align*}
If $X_i$ are unbounded, use the truncation arguments done while proving Elementary renewal theorem. Now $U(t)$ can be expressed as
\begin{align*}U(t) = N_t -1 +N_t^*\end{align*}
where $N_t^*$ is the number of times $S_n \leq t$ after having crossed $t$. Since $N_t^*$ is not greater than the number of points occuring after $N_t$ when the random walk is less than $S_{N_t}$, we get
\begin{align*}E[N_t^*] \leq E[\mbox{number of $n$ such that $S_n < 0$}]\end{align*}

Hence if we argue that RHS of above is finite, then
\begin{align*}\frac{u(t)}{t} \to \frac{1}{\mu}\end{align*}

From the first proposition in Random walks, we have $E[N] <\infty$ where $N$ is the first value of $n$ for which $S_n > 0$. At time $N$, with positive probability $1-p^*$, no future value of random walk will fall below $S_N$. Thus,
\begin{align*}E[\mbox{number of $n$ where $S_n < 0$}] \leq \frac{E[N|X_1<0]}{1-p^*} < \infty\end{align*}

Now follow the steps illustrated in the Blackwell renewal theorem (original) proof to arrive at the desired result.

\end{proof}
\end{document}
