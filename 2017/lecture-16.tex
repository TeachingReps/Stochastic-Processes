% !TEX spellcheck = en_US
% !TEX spellcheck = LaTeX
\documentclass[a4paper,10pt,english]{article}
\input{header}
\title{Lecture 16 : Evolution of Markov Processes}
\author{}
\begin{document}
\maketitle

\section{Regularity and Stationarity}
%\begin{defn} 
A CTMC is called \textbf{regular} if for all finite $t \in \R_+$, number of jumps $N(t)$ is almost surely finite. 
That is, for all $t \in \R_+$
\begin{align*}
\Pr\{ N(t) < \infty \} = 1.
\end{align*} 
%\end{defn}
\begin{lem} 
A homogeneous CTMC is regular if $\sup_{i \in E} \nu_i < \nu < \infty$. 
\end{lem}
\begin{proof}
By coupling, we can have a sequence of \textit{iid} random variables $\{\underline{T}_n: n \in \N\}$, 
such that $\underline{T}_n \leq T_n$ and $\E X_n = \nu$ for each $n \in \N$. 
Let $\underline{m}(t)$ be the associated renewal function with the sequence $\underline{T}$, 
then we can write 
\eq{
    \Pr\{N(t) < \infty\} &= \sum_{n \in \N_0}\Pr\{S_n \geq t\} = 1 + m(t) \leq 1 + \underline{m}(t).
}
\end{proof}
\begin{shaded*}
%\begin{exmp} 
Consider the following example of a non-regular CTMC, where for all $i \in \N$
\eq{
    p_{i,i+1}=1, \nu_i = i^2.
} 
Clearly, $\sup_{i \in E}\nu_i = \infty$, and hence it is not regular.
%\end{exmp}
\end{shaded*}

\subsection{Properties of transition matrix}
For each $t$, we have the transition matrix $P(t)$.
\begin{lem}[continuity]
Transition matrix $P(t)$ for a homogeneous CTMC $X$ is a continuous function of time $t \in \R_+$, such that
\eq{
    \lim_{t \downarrow 0}P(t) = I.
}
\end{lem}
\begin{proof}
It follows from continuity of probability functions and alternate characterization of homogeneous CTMC.
\end{proof}
\begin{lem}[semigroup property]
Transition matrix $P(t)$ satisfies the semigroup property
\eq{
    P(s+t) &= P(s)P(t).
}
\end{lem}
Since each entry of $P(t)$ is a probability, this leads to characterization of $P(t)$ completely. 
\begin{proof}
From homogeneity of Markov chains, we can write the $(i,j)$th entry of $P(s+t)$ as
\eq{
    P_{ij}(0,s+t) &= \sum_{k \in E}P_{ik}(0,s)P_{kj}(s,s+t) =  \sum_{k \in E}P_{ik}(0,s)P_{kj}(0,t) = [P(s)P(t)]_{ij}.
}
\end{proof}
For a homogeneous CTMC with transition matrix $P(t)$, the \textbf{generator matrix} $Q \in \R^{E \times E}$ is defined as the following limit when it exists 
\eq{
    Q &\triangleq \lim_{t \downarrow 0}\frac{P(t) - I}{t}.
}
\begin{thm} 
For a homogeneous CTMC, the generator matrix exists and is defined in terms of sojourn time rates $\{\nu_i: i \in E\}$, and jump transition matrix $p = \{p_{ij}: i,j \in E\}$ as
\begin{xalignat*}{3}
&Q_{ii} = -\nu_i,&&Q_{ij} = \nu_ip_{ij}.
\end{xalignat*}
\end{thm}
\begin{proof}
We can expand the $(i,j)$th entry of transition matrix in terms of disjoint events  $\{N(t) = n\}$ as  
\eq{
    P_{ij}(t) &= \Pr\{X(t)=j|X(0) = i\} = \sum_{n \in \N_0}\Pr\{X(t)=j, N(t) = n|X(0) = i\}.
}
We can write the upper and lower bound as 
\eq{
    \sum_{n = 0}^{1}\Pr\{X(t)=j, N(t) = n|X(0) = i\} &\leq P_{ij}(t) \leq \sum_{n = 0}^{1}\Pr\{X(t)=j, N(t) = n|X(0) = i\} + \Pr\{N(t) \geq 2\}.
}
For $t > 0$, we can compute for $j \neq i \in E$
\begin{xalignat*}{3}
&\Pr\{X(t)= i, N(t) = 0 | X(0) = i\} = e^{-\nu_i t}, && \Pr\{X(t) = i, N(t) = 1| X(0) = i\} = 0,\\
&\Pr\{X(t)= j, N(t) = 0 | X(0) = i\} = 0, && \Pr\{X(t) = j, N(t) = 1| X(0) = i\} = p_{ij}\int_{0}^t\nu_ie^{-\nu_j(t-u)}e^{-\nu_iu}du.
\end{xalignat*}
Since $\{N(t) \geq 2\}$ is of order $o(t)$ for small $t$, we can write
\eq{
    \frac{P_{ij}(t) - I_{ij}}{t} &= -\left(\frac{1-e^{-\nu_it}}{t}\right)I_{ij} + \nu_ip_{ij}\frac{(e^{-\nu_j}-e^{-\nu_it})}{(\nu_i-\nu_j)t}(1-I_{ij}) + o(t).
    %\begin{cases}
    %\frac{1-e^{-\nu_it}}{t} + o(t) &i = j, \\
    %\frac{\nu_i(e^{-\nu_j}-e^{-\nu_it})}{(\nu_i-\nu_j)t}& i \neq j.
    %\end{cases}
}
Taking limit as $t \downarrow 0$, we get the result.
\end{proof}

\begin{cor}
For each state $i \in E$, the generator matrix $Q \in \R^{E \times E}$ for a homogeneous CTMC satisfies 
\begin{xalignat*}{5}
&0 \leq -Q_{ii} < \infty, && Q_{ij} \geq 0,&&\sum_{j \in E}Q_{ij} = 0.
\end{xalignat*}
\end{cor}

\subsection{Chapman Kolmogorov equations}
\begin{thm}[backward equation] For a homogeneous CTMC with transition matrix $P(t)$ and generator matrix $Q$, we have
\begin{align*}
%P'_{ij}(t)= \sum_{k \neq i}q_{ik}P_{kj}(t)-\nu_iP_{ij}(t) ,  i,j \in I
\frac{dP(t)}{dt}=QP(t), ~~t \geqslant 0.
\end{align*}
\end{thm}
\begin{proof} 
Using semigroup property of transition probability matrix $P(t)$ for a homogeneous CTMC,  
%we have
%\begin{align*}
%P_{ij}(t+h)=\sum_{k \in I}P_{ik}(h)P_{kj}(t),~~i,j \in I.
%\end{align*}
%Re-arranging terms, 
we can write
\begin{align*}
%P_{ij}(t+h)-P_{ij}(t)=\sum_{k \neq i}P_{ik}(h)P_{kj}(t)-(1-P_{ii}(h))P_{ij}(t).
\frac{P(t+h) - P(t)}{h} &= \frac{(P(h)- I)}{h}P(t). % = P(t)\frac{(P(h) - I)}{h}.
\end{align*}
%Dividing above equation by $h$,  and 
Taking limits $h \downarrow 0$ and exchanging limits and summation, we get 
\begin{align*}
\frac{dP_{ij}(t)}{dt} = \sum_{k \neq i}Q_{ik}P_{kj}(t)-\nu_iP_{ij}(t). 
\end{align*}
Now the exchange of limit and summation has to be justified. For any finite subset $F \subset E$, we have
\begin{align*}
\liminf_{h \downarrow 0} \sum_{k \neq i}\frac{P_{ik}(h)}{h}P_{kj}(t) \geq \sum_{k \in F\setminus \{i\} }\liminf_{h \downarrow 0}\frac{P_{ik}(h)}{h}P_{kj}(t) = \sum_{k \in F\setminus \{i\}}Q_{ik}P_{kj}(t).
\end{align*}
Since, above is true for any finite set $F \subset E$, taking supremum over increasing sets $F$, we get the lower bound.
%\begin{align*}
%\liminf_{h \downarrow 0} \sum_{k \neq 1}\frac{P_{ik}(h)}{h}P_{kj}(t) \geq \sum_{k \neq i}Q_{jk}P_{kj}(t).
%\end{align*}
%%Suffices to show that $\limsup_{h \rightarrow 0} \sum_{k \neq 1}\frac{P_{ik}(h)}{h}P_{kj}(t) \leq \sum_{k \neq 1}q_{jk}P_{kj}(t)$. 
For the upper bound, we observe for any finite subset $F \subseteq E$
\begin{align*}
\limsup_{h \downarrow 0}\sum_{k \neq i}\frac{P_{ik}(h)}{h}P_{kj}(t) &\leq \limsup_{h \downarrow 0}\left(\sum_{k \in F\setminus \{i\}}\frac{P_{ik}(h)}{h}P_{kj}(t)+\sum_{k \notin F\setminus\{i\} }\frac{P_{ik}(h)}{h}\right)\\
& = \limsup_{h \downarrow 0}\left(\sum_{k \in F\setminus \{i\}}\frac{P_{ik}(h)}{h}P_{kj}(t)+\frac{1-P_{ii}(h)}{h} -\sum_{k \in F\setminus \{i\}}\frac{P_{ik}(h)}{h} \right)\\
&= \sum_{k \in F\setminus \{i\}}Q_{ik}P_{kj}(t)+\nu_i- \sum_{k \in F\setminus \{i\}}Q_{ik}. %&=\sum_{k \neq 1}q_{ik}P_{kj}(t). 
\end{align*}
\end{proof}
\begin{thm}[forward equation] 
%Under suitable regularity conditions, 
For a homogeneous CTMC with transition matrix $P(t)$ and generator matrix $Q$, we have 
\eq{
    \frac{dP(t)}{dt} &=P(t)Q.
}
%$P'_{ij}(t)=\sum_{k \neq i}P_{ik}(t)q_{kj}-P_{ij}(t)\nu_i$, i.e. $\frac{dP(t)}{dt}=P(t)Q$.
\end{thm}
\begin{proof}
Using semigroup property of transition probability matrix $P(t)$ for a homogeneous CTMC,  
we can write
\begin{align*}
\frac{P(t+h) - P(t)}{h} &= P(t)\frac{(P(h) - I)}{h}.
\end{align*}
Taking limits $h \downarrow 0$, we get 
\begin{align*}
\frac{dP_{ij}(t)}{dt} = \sum_{k \neq j}P_{ik}(t)Q_{kj}-\nu_jP_{ij}(t). 
\end{align*}
By taking limiting value for increasing sequence of finite sets $F \subseteq E$, we obtain the lower bound 
\eq{
    \sum_{k \neq j}P_{ik}(t)Q_{kj} &\leq \liminf_{h \downarrow 0} \sum_{k \neq j}P_{ik}(t)\frac{P_{kj}(h)}{h}.
}
To obtain the upper bound, we observe for any finite subset $F \subseteq E$, 
\eq{
    \limsup_{h \downarrow 0}\sum_{k \neq i}P_{ik}(t)\frac{P_{kj}(h)}{h} &\leq 
    %\limsup_{h \downarrow 0}\left(\sum_{k \in F\setminus \{i\}}P_{ik}(t)\frac{P_{kj}(h)}{h}+\sum_{k \notin F\setminus\{i\} }\frac{P_{kj}(h)}{h}\right)\\& = 
    \limsup_{h \downarrow 0}\left(\sum_{k \in F\setminus \{j\}}P_{ik}(t)\frac{P_{kj}(h)}{h}+\frac{1-P_{jj}(h)}{h} -\sum_{k \in F\setminus \{j\}}\frac{P_{kj}(h)}{h} \right).
    %\\&= \sum_{k \in F\setminus \{j\}}P_{ik}(t)Q_{kj}+\nu_j- \sum_{k \in F\setminus \{j\}}Q_{kj}.
} 
\end{proof}

\begin{cor}
For a homogeneous CTMC with finite state space $E$, the transition matrix $P(t)$ and generator matrix $Q$, we have
\eq{
    P(t) &= e^{tQ} = I + \sum_{n \in \N}\frac{t^nQ^n}{n!},~t\geqslant 0.
}
\end{cor}
\begin{cor}
%For an irreducible and aperiodic 
For a homogeneous CTMC with finite state space $E$, the transition matrix $P(t)$ and generator matrix $Q$, the stationary distribution satisfies
\begin{xalignat*}{3}
    &\pi Q = 0, &&\pi_i > 0, &&\sum_{i \in E}\pi_i = 1.
\end{xalignat*}
\end{cor}
\begin{proof}
We can define probability of being in state $j \in E$ at time $t$ by
\eq{
\pi_j(t) &= \Pr\{X(t) = j\}.% = \sum_{i \in E}\pi_i(0)P_{ij}(t).
}
By Markov property, we have $\pi(t) = \{\pi_j(t): j \in E\}$ by
\eq{
\pi(t) &= \pi(0)P(t).
}
For a stationary distribution, we have $\pi = \pi P(t)$ and taking derivatives on both sides, we get the result.
\end{proof}

\subsection{Transition graph}
The directed transition graph consists of vertex set $E$ and the edges being 
\eq{
\{(i,j): p_{ij} > 0, i \neq j\}.
}
The weights of the directed edges are given by $w_{ij} = \nu_ip_{ij}$. 
\appendix
\section{Generator matrix}
%\begin{defn}
A \textbf{generator matrix} denoted by $Q \in \R^{E \times E}$ is defined in terms of sojourn times $\{\nu_i, i \in E\}$ and jump transition probabilities $\{p_{ij}, i \neq j \in E\}$ of a CTMC as
\begin{enumerate}[i\_]
\item $q_{ii}= -\nu_i$,
\item $q_{ij}=\nu_i p_{ij}$. 
\end{enumerate}

%\end{defn}
\begin{lem} A matrix $Q$ is a generator matrix for a CTMC iff for each $i \in I$,
 \begin{enumerate}[i\_]
 \item $0 \leq -q_{ii} < \infty$, 
 \item $q_{ij} \geq 0$,
 \item $\sum_{j \in I}q_{ij}=0$.
 \end{enumerate}
 \end{lem}

 From the $Q$ matrix, we can construct the whole CTMC.  In DTMC, we had the result $P^{(n)}(i,j)=(P^n)_{i,j}$. We can generalize this notion  in the case of CTMC as follows: $P=e^{Q}\triangleq \sum_{k \in \mathbb{N}_0}\frac{Q^k}{k !}$.  Observe that $e^{Q_1+Q_2}=e^{Q_1}e^{Q_2},~ e^{nQ}=(e^Q)^n=P^n$.\\
 \begin{thm}
 Let $Q$ be a finite sized matrix. Let $P(t)=e^{tQ}$. Then $\{P(t),~ t \geq 0\}$ has the following properties:\begin{enumerate}
 \item {$P(s+t)=P(s)P(t),~ \forall s,~t$ (semi group property).}
 \item {$P(t),~t \geq 0$ is the unique solution to the forward equation, $\frac{dP(t)}{dt}=P(t)Q,~P(0)=I$.}
 \item {And the backward equation $\frac{dP(t)}{dt}=QP(t),~P(0)=I$.}\\
 \item {For all $k \in \mathbb{N}$, $\frac{d^kP(t)}{d^k(t)}|_{t=0}=Q^k$.}
 \end{enumerate}
 \end{thm}  
 \begin{proof}
 $\frac{dM(t)e^{-tQ}}{dt}=0,$ $M(t)e^{-tQ}$ is constant. $M(t)$ is any matrix satisfying the forward equation.
 \end{proof}
 \begin{thm}
 A finite matrix $Q$ is a generator matrix for a CTMC iff $P(t)=e^{tQ}$ is a stochastic matrix for all $t \geq 0$. 
 \end{thm}
 \begin{proof}
 $P(t)=I+tQ+O(t^2)$ ($f(t)=O(t) \Rightarrow \frac{f(t)}{t} \leq c,$ for small $t,~c < \infty$ ). $q_{ij} \geq 0$ if and only if $P_{ij}(t) \geq 0,~ \forall i \neq j$ and $t \geq 0$ sufficiently small. $P(t)=P(\frac{t}{n})^n$. Note that if $Q$ has zero row sums, $Q^n$ also has zero row sums.\\
 \begin{flalign*}
 \sum_j [Q^n]_{ij}&= \sum_j \sum_k [Q^{n-1}]_{ik}Q_{kj}= \sum_j \sum_k Q_{kj}[Q^{n-1}]_{ik}=0.\\
 \sum_{j}P_{ij}(t)&=1+\sum_{n \in \mathbb{N}} \frac{t^n}{n!}\sum_j [Q^n]_{ij}=1+0=1.
 \end{flalign*}  
 Conversely $\sum_{j}P_{ij}(t)=1,~ \forall t \geq 0$, then $\sum_jQ_{ij}= \frac{dP_{ij}(t)}{dt}=0$.
 \end{proof}
 \end{document}

