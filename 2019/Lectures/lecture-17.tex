% !TEX spellcheck = en_US
% !TEX spellcheck = LaTeX
%\documentclass[a4paper,10pt,english]{article}
\documentclass[all-lectures.tex]{subfiles}
%\input{header}
%\title{Lecture 01: Poisson Processes}
%\author{}
\setcounter{chapter}{4}

\begin{document}
%\maketitle

\chapter{Martingales}
\setcounter{section}{0}
\setcounter{subsection}{0}

\section*{\centering{Lecture 17 \linebreak }}

\section{Introduction}
Martingales are a very versatile tool in stochastic processes. 
We will use it to get several useful results in this course.

A discrete time stochastic process is $\{X_k, k\ge 0\}$ is a \textit{martingale} $w.r.t.$ filteration $\F_n=\{Y_0, Y_1, \dots, Y_ n\}$ if 
\begin{enumerate}
\item If $X_k$ is a function of $Y_1, Y_2, \dots, Y_k$.
\item $\E[|X_k|] < \infty$, \quad $\forall$ $k \ge 0$.
\item $\E[X_{k+1}|Y_1, Y_2, \dots, Y_k] = X_k$ \quad $a.s.$
\end{enumerate}
 If the equality in third condition is replaced by $\le$ or $\ge$, then the process is called a \textit{supermartingale} or a \textit{submartingale}, respectively.
\begin{exmp}
Let $Z_1, Z_2, \dots $ be $i.i.d.$, and $\E[Z_k]=0$, $S_n = \sum_{k=0}^{n} Z_k$,
\eq{
\E[S_{n+1}|Z_1, \dots, Z_n] &= \E[S_{n}+Z_{n+1}|Z_1, \dots, Z_n]\\
&= S_n + \E[Z_{n+1}|Z_1, \dots, Z_n]\\
&= S_n + \E[Z_{n+1}]\\
&= S_n.
}
Hence, $S_n$ is a martingale $w.r.t.$ $\{Z_1,Z_2 \dots, Z_n\}$.
\end{exmp}

\begin{exmp}
Let $Z_1, Z_2, \dots $ be $i.i.d.$, and $\E[Z_k]=0$,  $var(Z_k)= \sigma^2 < \infty$,  $S_n = \sum_{k=1}^{n} Z_k$, $S_0 =0$, $Z_0=0$, $X_n = S^2_n - n \sigma^2$.
Then
\eq{
\E[X_{n+1}|Z_1, \dots, Z_n] &= \E[S^2_{n+1}-(n+1) \sigma^2|Z_1, \dots, Z_n]\\
&= \E[(S_{n}+Z_{n+1})^2|Z_1, \dots, Z_n] - (n+1) \sigma^2\\
&= S^2_n - n \sigma^2\\
&= X_n.
}
Hence, $X_n$ is a martingale.
\end{exmp}

\begin{exmp}
Let $Z_0=0, Z_1, Z_2, \dots $ be $i.i.d.$, and $\E[e^{\theta Z_1}] < \infty$ for some $\theta >0$, $S_n = \sum_{k=0}^{n} Z_k$. $X_n = \frac{e^{\theta S_n}}{\E[e^{\theta Z_1}]^n}$,
\eq{
\E[X_{n+1}|Z_1, \dots, Z_n] &= \frac{\E[e^{\theta S_{n+1}}|Z_1, \dots, Z_n]}{\E[e^{\theta Z_1}]^{n+1}}\\
&= e^{\theta S_n} \frac{\E[e^{\theta Z_{n+1}}|Z_1, \dots, Z_n]}{\E[e^{\theta Z_1}]^{n+1}}\\
&= \frac{e^{\theta S_n}}{\E[e^{\theta Z_1}]^n}\\
&= X_n.
}
Hence, $X_n$ is a martingale.
\end{exmp}

\begin{exmp}
	$Y_0 = 1, Y_1, Y_2, \dots$	independent, $\E[Y_i] = 1$, $X_0 =1$, $X_n = \prod_{k=1}^{n} Y_k$. Then
	\eq{
		\E[X_{n+1}|Y_1, Y_2, \dots, Y_n] &= \E[\prod_{k=1}^{n} Y_k | Y_1, Y_2, \dots, Y_n]\\
		&= \prod_{k=1}^{n} Y_k \E[Y_{k+1}]\\
		&= \prod_{k=1}^{n} Y_k\\
		&= X_n.
	}
	Hence, $X_n$ is a martingale.
\end{exmp}

\begin{exmp}
Let $\{X_k, k\ge 0\}$ be a martingale $w.r.t.$ filteration $\F_n=\{Y_0, Y_1, \dots, Y_ n\}$. Let $\phi:\R \to \R$, $Z_n = \phi(X_n)$,
\eq{
\E[Z_{n+1}|Y_0, Y_1, \dots, Y_n] &= \E[\phi(X_{n+1})|Y_0, Y_1, \dots, Y_n]\\
}
If $\phi$ is a convex function, then by Jensen's inequality
\eq{
\E[\phi(X_{n+1})|Y_0, Y_1, \dots, Y_n] \ge \phi(\E[X_{n+1}|Y_1, \dots, Y_n]) = \phi(X_n)
}
Hence, $\phi(X_n)$ is a submartingale.
\end{exmp}
If $\{X_n\}$ is a submartingle and $\phi$ convex, non decreasing,
\eq{
\E[Z_{n+1}|Y_0, Y_1, \dots, Y_n] &= \E[\phi(X_{n+1})|Y_1, \dots, Y_n]\\
&\ge \phi(\E[X_{n+1}|Y_1, \dots, Y_n])\\
&\ge \phi(X_n).
}
Hence, $\phi(X_n)$ is a submartingale.

\section{Optional Sampling Theorem}


If $\{X_k\}$ is a martingale, $w.r.t.$ $\{Y_n\}$ then, for $n>k$
\eq{
E[X_{n}] = \E[\E[X_{n}|Y_1, Y_2, \dots, Y_k]] = E[X_{k}] = E[X_{k-1}] = \dots = \E[X_0]
}
For a submartingale, $E[X_{k+1}] \ge E[X_k] \ge \dots \ge \E[X_0]$.

\begin{prop}
If $\{X_n\}$ is a martingale $w.r.t.$ $\{Y_n\}$, $T$ a stopping time $w.r.t.$ $\{Y_n\}$, then $\E[X_{T \wedge n}] = \E[X_0]$ for all $n\ge0$.
\end{prop}
\begin{proof}
\eq{
X_{T \wedge n+1} -X_{T \wedge n} = (X_{n+1}-X_n) 1_{\{T>n\}}
}
Taking expectations,
\eq{
\E[X_{T \wedge n+1} -X_{T \wedge n}] = \E[(X_{n+1}-X_n) 1_{\{T>n\}}] = \E[\E[(X_{n+1}-X_n) 1_{\{T>n\}}|\F_n]]
}
Since $T$ is a stopping time $\{T \le n\}$ is a function of $(Y_1, Y_2, \dots, Yn) = \F_n$. Thus, $\{T \le n\}^c$ is also a function of $\F_n$.

Thus,
\eq{
\E[\E[(X_{n+1}-X_n) 1_{\{T>n\}}|\F_n]] = \E[1_{\{T>n\}} \E[(X_{n+1}-X_n)|\F_n]] = 0.
}
Therefore,
\eq{
\E[X_{T \wedge n+1}] = \E[X_{T \wedge n}] = \dots = \E[X_{T \wedge 0}] = \E[X_0].
}
\end{proof}
For a submartingale, the above proof gives 
\eq{
\E[X_{T \wedge n+1}] \ge \E[X_{T \wedge n}] \ge \dots \ge \E[X_{T \wedge 0}] \ge \E[X_0].	
}

Since,
\eq{
\lim_{n \to \infty} T(\omega) \wedge n = T(\omega),
}
\eq{
\lim_{n \to \infty} X_{T \wedge n (\omega)}(\omega) = X_{T(\omega)}(\omega) \quad a.s..
}
If 
\begin{align}
\label{eq1}	
\E[X_{T \wedge n}] \to \E[X_T] \enskip \text{as} \enskip n \to \infty,
\end{align}

then  from above proposition 
\begin{align}
\label{eq2}
\E[X_0] = \E[X_T].
\end{align}eqn{


Conditions for Eq (\ref{eq1}) to hold are,
\begin{itemize}
\item $T \le n_0$  $a.s.$ for some $n_0<\infty$.
 Then $X_{T \wedge n} = X_T$ $a.s.$ when $n\ge n_0$. Thus $\E[X_{T \wedge n}] = \E[X_T],$ $\forall$ $n \ge n_0$.
\item $X_n \le Z$ $a.s.$ $\forall$ $n \ge n_0$ and $\E[z] < \infty$. Then $X_{T \wedge n} \le Z$ $a.s.$ $\forall$ $n$. Thus $X_{T \wedge n} \to X_T$ $a.s.$, and dominated convergence theorem, implies $\E[X_{T \wedge n}] \to \E[X_T]$.
\end{itemize}

\begin{prop}
If $\{X_n\}$ is a martingale,  $\E[|X_n - X_{n-1}|\mid \F_n] \le c < \infty$, $\forall$ $n \ge 1$ and $\E[T] < \infty$ then $\E[X_T] = \E[X_0]$.\\
\end{prop}
\begin{proof}
Define $Z = |X_0| + |X_1-X_0| + \dots + |X_T - X_{T-1}|$. We have
\eq{
X_{T \wedge n} &= (X_{T \wedge n} - X_{(T \wedge n)-1}) + (X_{(T \wedge n)-1} - X_{(T \wedge n)-2}) + (X_1-X_0) + X_0\\
&\le |X_{T \wedge n} - X_{(T \wedge n)-1}| + |X_{(T \wedge n)-1} - X_{(T \wedge n)-2}| + |X_1-X_0| + |X_0| \le Z\\
}
Thus if we show $\E[Z] < \infty$, we will have the proof from the above result. But,
\eq{
\E[Z] &= \E[|X_0|] +  \E[|X_1 - X_0|] + \dots + \E[|X_T- X_{T-1}|]\\
&= \E[|X_0|] + \E[\sum_{k=1}^{\infty} |X_k - X_{k-1}| 1_{\{T \ge k\}}]\\
&= \E[|X_0|] + \sum_{k=1}^{\infty} \E[\E[|X_k - X_{k-1}| 1_{\{T \ge k\}}|\F_{k-1}]]\\
&= \E[|X_0|] + \sum_{k=1}^{\infty} \E[1_{\{T \ge k\}}] \E[|X_k - X_{k-1}|\F_k]\\
&\le \E[|X_0|] + c \E[T]\\
&< \infty.
}\end{proof}
\end{document}