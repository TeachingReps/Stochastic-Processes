% !TEX spellcheck = en_US
% !TEX spellcheck = LaTeX
\documentclass[a4paper,10pt,english]{article}
\input{header}
\title{Lecture 08: Inspection Paradox and Limiting Mean Excess Time}
\author{}

\begin{document}
\maketitle

\section{Key Renewal Theorem}

%\subsection{Directly Riemann Integrable}
%\begin{defn}%[Directly Riemann Integrable] 
For each $\delta > 0$ and $n \in \N$, we define intervals $I(n,\delta) = [(n-1)\delta, n\delta)$ that partition the positive axis $\R_+ = [0, \infty)$. 
Let $h: \R_+ \mapsto \R$ be a function bounded over finite intervals, denoting 
\begin{xalignat*}{3}
&\underline{m}(h,n,\delta) = \inf\{h(u): u \in I(n,\delta)\} &&\overline{m}(h,n,\delta) = \sup\{h(u): u \in I(n,\delta)\}.
\end{xalignat*}
A function $h: \R_+ \mapsto \R$ is \textbf{directly Riemann integrable} and denoted by $h \in \D$ if the partial sums obtained by summing the infimum and supremum of $h$, 
taken over intervals obtained by partitioning the positive axis, are finite and both converge to the same limit, for all finite positive interval lengths. That is,
\begin{equation*}
\lim_{\delta \to 0} \delta \sum_{n \in \N}\overline{m}(h,n,\delta)=\lim_{\delta \to 0} \delta \sum_{n \in \N} \underline{m}(h,n,\delta).  
\end{equation*}   
 If both limits exist and are equal, then the integral value is equal to the limit. 
%\end{defn}
\begin{shaded*}
We compare the definitions of directly Riemann integrable and Riemann integrable functions. 
For a finite positive $M$, a function $g: [0, M] \rightarrow \R $ is Riemann integrable if 
\begin{align*}
\lim_{\delta \to 0} \delta \sum_{n \leq M/\delta}\overline{m}(g,n,\delta) &=\lim_{\delta \to 0} \delta \sum_{n \leq M/\delta}\underline{m}(g,n,\delta). 
\end{align*} 
In this case, the limit is the value of the integral. 
For $h$ defined on $\R_+$, 
\begin{align*}
\int_{u \in \R_+}h(u)du &= \lim_{M \rightarrow \infty}\int_{0}^{M}h(u)du, 
\end{align*}
if the limit exists. For many functions, this limit may not exist.

%\begin{rem}
A directly Riemann integrable function over $\R_+$ is also Riemann integrable, but the converse need not be true. 
For instance, consider the following Riemann integrable function
\begin{align*}
h(t) &= \sum_{n\in\N}1\left\{t \in \left[n-\frac{1}{(2n^2)},\,n+\frac{1}{(2n^2)}\right]\right\}
\end{align*} is Riemann integrable, but $\delta \sum_{n \in \N}\overline{m}(h,n,\delta)$ is always infinite for every $\delta>0.$
%\end{rem}  
\end{shaded*}
\begin{prop}%[Sufficiency for Directly Riemann Integrable] 
Following are sufficient conditions for a function $h$ to be directly Riemann integrable.
  \begin{enumerate}
  \item If $h$ is bounded and continuous and $h$ is non increasing. 
  \item If $h$ is bounded above by a directly Riemann integrable function.
	\item If $h$ is non-negative, non-increasing, and with bounded integral.
  \end{enumerate}
\end{prop}
\begin{prop}[Tail Property] If $h$ is non-negative, directly Riemann integrable, and has bounded integral value, then 
\begin{equation*}
\lim_{t \rightarrow \infty} h(t)=0.
\end{equation*}
\end{prop}

\begin{thm}[Key Renewal Theorem] 
Consider a renewal process with renewal function $m(t)$, and the mean and the distribution of inter-renewal times being denoted by $\mu$ and $F$ respectively. 
If $F$ is non-lattice and $F(\infty) = 1$, then for any $h \in \D$, we have 
%Denoting mean of inter-renewal time by $\mu$, we have for non-lattice $F$
%Let $N(t)$ be a renewal process having mean $m(t)$, and \emph{iid} inter-arrival times with mean $\mu$ and distribution function $F$. If $F$ is non-lattice, and if a function $h(t)$ is directly Riemann integrable, then
\begin{equation}
\label{eqn:Key Renewal Theorem}
\lim_{t \rightarrow \infty} \int_{0}^{\infty}h(t-x)dm(x)=\frac{1}{\mu}\int_{0}^{\infty}h(t)dt. 
\end{equation}
If $F$ is lattice with period $d$ and $\sum_{k \in \N_0}h(t+kd)$ converges, then 
\begin{align*}
\lim_{n \rightarrow \infty} \int_{0}^{\infty}h(t+nd-x)dm(x)=\frac{d}{\mu}\sum_{n \in \N_0}h(t+kd). 
\end{align*}
%where 
%\begin{xalignat*}{3}
%&m(t) = \sum_{n \in \N}F_n(t),&& \mu= \int_{0}^{\infty}\bar{F}(t).
%\end{xalignat*}
\end{thm}
%\begin{proof}
%We know that $m \ast F = m - 1$, so $m \ast (1- F) = 1$. 
%Since the function $1-F$ is monotone, 
%\begin{align*}
%1 &= \int_0^tdm(s)[1-F(t-s)] \geq [m(t) - m(t-b)](1-F(b)),
%\end{align*}
%where $b$ is chosen so that $F(b) < 1$. Hence, we have
%\begin{align*}
%\sup_{t}[m(t) - m(t-b)] = \beta_b < \infty.
%\end{align*}
%\end{proof}
\begin{prop}[Equivalence] Blackwell's theorem and key renewal theorem are equivalent.
\end{prop}
\begin{proof} Let's assume key renewal theorem is true. We select $h$ as a simple function with value unity on interval $[0, a]$ and zero elsewhere. That is,
\begin{equation*}
h(x) = 1_{\{ x \in [0,a]\}}.
\end{equation*}
It is easy to see that this function is directly Riemann integrable. %With this selection of $h$, Blackwell's theorem follows.

To see how we can prove the key renewal theorem from Blackwell's theorem, observe from Blackwell's theorem that,
\begin{align*}
\lim_{t \to \infty}\frac{dm(t)}{dt} \stackrel{(a)}= \lim_{a \to 0}\lim_{t \to \infty} \frac{m(t
+a)-m(t)}{a}=\frac{1}{\mu}.
\end{align*}     
where in $(a)$ we can exchange the order of limits under certain regularity conditions. 
We defer the formal proof for a later stage.
\end{proof}
%\begin{rem} 
Key renewal theorem is very useful in computing the limiting value of some function $g(t)$, probability or expectation of an event at an arbitrary time $t$, for a renewal process. This value is computed by conditioning on the time of last renewal prior to time $t$.
%\end{rem}

%\section{Key Renewal Theorem and Applications}
%
%\subsection{Key Renewal Theorem}
%\begin{thm}[Key Renewal Theorem] Let $N(t)$ be a renewal process having mean $m(t)$, and \emph{iid} inter-arrival times with mean $\mu$ and distribution function $F$. If $F$ is non-lattice, and if a function $h(t)$ is directly Riemann integrable, then
%\begin{equation}
%\label{eqn:Key Renewal Theorem}
%\lim_{t \rightarrow \infty} \int_{0}^{\infty}h(t-x)dm(x)=\frac{1}{\mu}\int_{0}^{\infty}h(t)dt,
%\end{equation}
%where 
%\begin{xalignat*}{3}
%&m(t) = \sum_{n \in \N}F_n(t),&& \mu= \int_{0}^{\infty}\bar{F}(t).
%\end{xalignat*}
%\end{thm}
%%\textbf{Remark:} and we can deduce one theorem from the other. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Alternating Renewal Processes}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Alternating renewal processes form an important class of renewal processes, and model many interesting applications. We find one natural application of  key renewal theorem  in this section. 
\begin{defn}[Alternating Renewal Process] Let $\{(Z_n,Y_n),~n \in \N\}$ be an \emph{iid} random process, where $Y_n$ and $Z_n$ are not necessarily independent. A renewal process where each inter-arrival time $X_n$ consist of ON time $Z_n$ followed by OFF time $Y_n$, is called an \textbf{alternating renewal process}. We denote the distributions for ON, OFF, and renewal periods by $H, G$, and $F$, respectively. Let 
\begin{equation*}
P(t)=\Pr\{\text{ON at time}~ t\}.
\end{equation*}
\end{defn}
%Let $Y_n \sim G$, $Z_n \sim H, F \sim Z_n+Y_n \triangleq X_n$. The random variable $Z_n$ denotes the ON time of a system and $Y_n$ denotes the OFF time of the system. Let $P(t)=P(\text{ON at time}~ t)$.

\begin{rem}
To see that the alternating renewal process is indeed a renewal process, it needs to be established that $\{X_n:n\in\mathbb{N}\}$ is an \emph{iid} sequence. But this trivially follows from the fact that $\{f(Y_n,Z_n):n\in\mathbb{N}\}$ is an \emph{iid} sequence whenever $\{(Z_n,Y_n),~n \in \N\}$ is an \emph{iid} sequence. Let $f(a,b) = a+b$ to see that $\{X_n:n\in\mathbb{N}\}$ is an \emph{iid} sequence.
\end{rem}

\begin{thm}[ON Probability] \label{Thm:OnProbability}
If $\E[Z_n+Y_n]< \infty $ and $F$ is non-lattice, then
\begin{equation*}
P(t) = \bar{H}(t)+\int_{0}^{t}\bar{H}(t-y)dm(y).
\end{equation*}
\end{thm} 
\begin{proof} To find time dependent probability $P(t)$, we can partition the event of system being ON at time $t$ on value of last renewal time $S_{N(t)}$. That is, we can write
\begin{equation*}
\{\text{ON at time}~ t\} =\bigcup_{y \in [0, t)}\{\text{ON at time } t, S_{N(t)} = y\}.% = \bigcup_{y \in [0, t)}\{Z_1 > t- y, S_{N(t)} = y\}.
\end{equation*}
Since any ON time is possibly only dependent on the corresponding OFF time and no past renewal times, conditioned on $\{S_{N(t)} = y \}$, the system stays ON at time $t$ \emph{iff} ON time is longer than $t-y$ conditioned on renewal time being larger than $t-y$. That is, 
\begin{equation*}
\{\text{ON at time } t| S_{N(t)} = y\} =\{Z_1 > t - y| Z_1 + Y_1 > t-y\}.
\end{equation*}
Since, for $y>0$, we have $\Pr\{Z_1 > t - y| Z_1 + Y_1 > t-y\} = \frac{\bar{H}(t-y)}{\bar{F}(t-y)}$, it follows that
\begin{equation*}
P(t) = \bar{H}(t)+ \int_{0}^t {\bar{H}(t-y)}{\bar{F}(t-y)}dF_{S_{N(t)}}(y)
\end{equation*}
In view of the density of $S_{N(t)}$ from Remark~\ref{Remark:DensityLastRenewal}, the result follows.
\end{proof}

\begin{cor}[Limiting ON Probability]
\label{cor:Limiting ON probability}
If $\E[Z_n+Y_n]< \infty $ and $F$ is non-lattice, then
\begin{equation*}
\lim_{t \rightarrow \infty}P(t)=\frac{\E[Z_n]}{\E[Y_n]+\E[Z_n]}.
\end{equation*}
\end{cor}
\begin{proof} Since $H$ is the distribution function of the non-negative random variable $Z_n$, it follows that 
\begin{align*}
\lim_{t \rightarrow \infty}\bar{H}(t) = 0, \text{ and } \int_0^\infty \bar{H}(t)dt = E[Z_n].
\end{align*}
Applying key renewal theorem to Theorem~\ref{Thm:OnProbability}, we get the result.
%\begin{align*}
%P(t)&= \Pr\{\text{ON at time t}, S_{N(t)}=0\}+\Pr\{\text{ON at time t}, S_{N(t)}>0\}\\
%&=\Pr\{\text{ON at time t}, S_{N(t)}=0\}+\int_{y=0}^{t}\Pr\{\text{ON at time t}| S_{N(t)}=y\}dF_{S_{N(t)}}(y)\\
%&=\Pr\{Z_1>t)+\int_{y=0}^{t}\Pr\{Z>t-y| Z+Y > t-y\}dF_{S_{N(t)}}(y)\\
%&\stackrel{(a)}{=}\bar{H}(t)+\int_{y=0}^{t}\frac{\bar{H}(t-y)}{\bar{F}(t-y)}\bar{F}(t-y)dm(y)\\
%&= \bar{H}(t)+\int_{y=0}^{t}\bar{H}(t-y))dm(y),\\
%\end{align*}
%where $(a)$ follows from the remark following Theorem 3.Now apply key renewal theorem to obtain the required result. Since $\bar{H}(t) \rightarrow 0$ as $t \rightarrow \infty$, we get
%\begin{flalign}
%P(t) \rightarrow \frac{\int_{0}^{\infty}\bar{H}(t)dt}{\mu}=\frac{\E[Z_n]}{\E[Y_n]+\E[Z_n]}.
%\end{flalign}
\end{proof}

Many processes of practical interest can be modeled by an alternate renewal process. 
\begin{exmp}[Age and Excess Time] Consider a renewal process and let $A(t)$ be the time from $t$ since the last renewal and $Y(t)$ be the time from $t$ till the next renewal. That is,
\begin{align*}
Y(t) &=S_{N(t)+1}-t,\\
A(t) &=t-S_{N(t)}.
\end{align*}   
Suppose we need to find $\lim_{t \to \infty}\Pr\{A(t) \leq x\}$ for some fixed  x. Now, observe that $\Pr\{A(t) \leq x\}=\E[1_{\{A(t) \leq x\}}]$ which is the mean time when the ``age at $t$" is less than $x$ which is equal to $\E[\min\{x,X\}]$. Hence, we get\\
\begin{equation*}
\lim_{t \rightarrow \infty} \Pr\{A(t) \leq x\} =\frac{\E \min\{x,X\}}{\E X} = \frac{\int_{0}^{x}\bar{F}(t)dt}{\mu}.
\end{equation*}  
\end{exmp}
It is to be mentioned that $\Pr\{Y(t)\leq x\}$ also yield the same limit as $t \to \infty$. This can be observed by noting that if we consider the reversed processes (an identically distributed renewal process), $Y(t)$,  the ``excess life time" at $t$ is same as the age at $t$, $A(t)$ of the original process.

Another way of evaluating $\lim_{t\to \infty} \Pr\{A(t)\leq x\}$ is to note that $\{A(t)\leq x\} = \{S_{N(t)}\geq t-x\}$ from which it follows that
\begin{align*}
\Pr\{A(t)\leq x\} &= \Pr\{S_{N(t)}\geq t-x\} \\
& = \int_{-\infty}^{\infty} \Pr\{S_{N(t)} \geq t-x | S_{N(t)}=y\}dF_{S_{N(t)}}(y) \\
& = \int_{t-x}^\infty dF_{S_{N(t)}}(y)\\
&\stackrel{(a)}{=} \int_{-\infty}^x \bar F(u)dm(u)\\
&= \int_{-\infty}^0 dm(u) + \int_{0}^x \bar{F}(u)dm(u)\\
& = \int_{0}^x \bar{F}(u)dm(u),
\end{align*}
where $(a)$ follows from a change of variable $u = t-y$. In the limit, $dm(u) \to \frac{du}{\mu}$, as $t \to \infty$, and hence 
\begin{equation}
\lim_{t\to \infty} \Pr\{A(t)\leq x\} = \frac{1}{\mu}\int_{0}^x \bar{F}(u)du
\end{equation}
%\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5  
\section{The Inspection Paradox}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Define $X_{N(t)+1}=A(t)+Y(t)$ as the length of the renewal interval containing $t$, in other words, the length of current renewal interval. Inspection paradox says that $P(X_{N(t)+1} >x)\geq \bar{F}(x)$. That is, for any $x$, the length of the current renewal interval to be greater than $x$ is always more likely than that for an ordinary renewal interval. Formally,
\begin{flalign*}
\Pr\{X_{N(t)+1}>x\}&= \int_{0}^t\Pr\{X_{N(t)+1} > x | S_{N(t)} = y, N(t)=n\}dF_{(S_{N(t)}, N(t))}.
%&= P(X_2 >x)\\
%&= \bar{F}(x).
\end{flalign*}
Now we have,
\begin{flalign*}
\Pr\{X_{N(t)+1}>x | S_{N(t)}=y, N(t)=n\} & = \Pr\{X_{N(t)+1}>x | X_1+\cdots+X_n=y, X_{n+1}>t-y\} \\
& = \Pr\{X_{n+1}>x | X_{n+1}>t-y\} \\
& = \frac{\Pr\{X_{n+1}>\text{max}(x,t-y)\}}{\Pr\{X_{n+1}>t-y\}} \\
& \geq \bar{F}(x). 
\end{flalign*}
So we get that,
\begin{flalign*}
\Pr\{X_{N(t)+1}>x\}\geq \Pr\{X_{1}>x\}.
\end{flalign*}
One can also look into a weaker version of inspection paradox involving
the limiting distribution of $X_{N(t)+1}$, consider an alternating 
renewal process for which the ON time is the total time of the cycle if that 
total time is greater than $x,$ and zero otherwise. The system is either totally ON 
during a cycle (if the renewal interval is greater than $x$), or totally OFF 
otherwise. Formally,
\begin{align*}
Z_n= &\text{ ON time in $n^{\text{th}}$ cycle} = X_n \mathbb{I}_{X_n>x} \\
Y_n= &\text{ OFF time in $n^{\text{th}}$ cycle} = X_n \mathbb{I}_{X_n\leq x}.
\end{align*}
Now we have,
\begin{flalign*}
\Pr \{X_{N(t)+1}>x\} &= \Pr\{\text{length of the interval containing } t>x\}\\
&= \Pr\{ \text{on at time } t \}.
\end{flalign*}

From alternating renewal process theorem, we conclude that 
\begin{flalign*}
\lim_{t\to \infty}\Pr\{X_{N(t)+1}>x\} &= \frac{\E[\text{on time in cycle}]}{\mu} \\
&= \frac{\E[X\mathbb{I}_{X>x}]}{\mu}\\
&= \frac{\int_{x}^\infty y dF(y)}{\mu}\\
&\geq \Pr[X_1\geq x],
\end{flalign*}
where the last step follows from Chebyshev's inequality stated below.

\begin{rem}
The inspection paradox states, in essence, that if we pick a point $t$, it is more likely that an inter-renewal interval with larger length will contain $t$ than the smaller ones. For instance, if $X_i$ were equally likely to be $\epsilon$ or $1-\epsilon$, we see that the mean of any inter arrival length is 1 for any value of $\epsilon\in(0,1)$. However, for small values $\epsilon$, it is more likely that a given $t$ will be in an interval of length $1-\epsilon$ than in an interval of length $\epsilon$.
\end{rem}

\subsubsection*{Chebyshev's Sum Inequality:}
 If $f:\mathbb{R} \rightarrow \mathbb{R}^{+}$ and $g : \mathbb{R} \rightarrow \mathbb{R}^{+}$ are functions with the same
 monotonicity then for any random variable $X$, $f(X)$ and $g(X)$ are positive and
 $$\E[f(X)g(X)] \geq \E[f(X)]\E[g(X)].$$
\textbf{Remark:} \\
 This inequality gives us that
 $$\E[X\mathbb{I}_{X\geq x}] \geq \E[X]\Pr[X\geq x].$$

\subsection{Example:}
 Suppose the number of commodities desired by a customer at a store follows a distribution $G$. The ordering policy of the store is as follows: For some fixed $s,~S$, if the inventory level after serving a customer is $x$, then the amount ordered is
 
 

     \begin{displaymath}
        \left\{
         \begin{array}{lr}
           S-x & \text{if } x <s\\
           0 & \text{if } x \geq s
         \end{array}
       \right.
    \end{displaymath} 

Let $L(t)$ denote the inventory level at time $t$. We are interested in finding $\lim_{t \rightarrow \infty}\mathbb{P}(L(t) \geq y)$. 
Let $X_n$ denote inter-restocking times. Let $\{L(t)\geq y\}$ denote ON period. $X_n$ forms an 
alternating renewal process with the above mentioned ON time. 
From alternating renewal process theorem, we have 

\begin{flalign*}
\lim_{t \rightarrow \infty}\mathbb{P}(L(t) \geq y) &= \frac{\mathbb{E}[\text{ON time}]}{\mathbb{E}[X_1]}\\
&=\frac{\mathbb{E}[\sum_{i=1}^{N_y}X_i]}{\mathbb{E}[\sum_{i=1}^{N_s}X_i]}=\frac{\mathbb{E}[N_x]}{\mathbb{E}[N_s]}.
\end{flalign*}

where $N_y= \min\{n \in \mathbb{N}: \sum_{i=1}^{n}D_i > S-y\}$  and $D_1,D_2 \hdots$ denote the successive customer demands. Since $D_i$ are iid, we can interpret $N_y-1$ as the number of renewals till time $S-y$. $D_i$ is the inter arrival time of the process. Thus   

\begin{flalign*}
\lim_{t \rightarrow \infty}\mathbb{P}(L(t) \geq y) =\frac{m_G(S-x)+1}{m_G(S-s)+1}, s \leq x \leq S.
\end{flalign*}
\section{Limiting Mean Excess Time}
Consider a nonlattice renewal process and we are interested in computing the mean excess time of the process. We start by writing the renewal equation of mean excess life time, $\mathbb{E}[Y(t)]$.
\begin{flalign*}
\mathbb{E}[Y(t)]&= \mathbb{E}[Y(t)|S_{N(t)}=0]F^c(t)+ \int_{0}^{t} \mathbb{E}[Y(t)|S_{N(t)}=y]F^c(t-y)dm(y)\\
&=\mathbb{E}[X_1-t |X_1>t]F^c(t)+ \int_{0}^{t} \mathbb{E}[X-(t-y)|X>t-y]F^c(t-y)dm(y).
\end{flalign*}
From Key Renewal theorem, we have 

\begin{flalign*}
\lim_{t \rightarrow \infty}\mathbb{E}[Y(t)]&=\frac{1}{\mu} \int_{0}^{\infty} \mathbb{E}[X-t|X-t >0]F^c(t) dt\\
&= \frac{1}{\mu} \int_{t=0}^{\infty} \int_{x=t}^{\infty}(x-t) dF(x) dt\\
&= \frac{1}{\mu} \int_{x=0}^{\infty} \int_{t=0}^{x}(x-t) dF(x) dt\\
&= \frac{\mathbb{E}[X^2]}{2\mu}.
\end{flalign*}

\begin{rem}
It can also be established that $\lim_{t\to \infty}\frac{\int_0^t Y(\tau) d\tau}{t} = \frac{EX^2}{2\mu}$ since, for each sample path $\{Y(t)= y(t)\}$ and sample values $\{x_i,i\in\mathbb{N}\}$, we have $\int_0^ty(\tau)d\tau = \frac{1}{2}\sum_{i=1}^{n(t)}x_i^2+\int_{\tau=s_{n(t)}}^t y(\tau)d\tau$.
\end{rem}



\begin{prop}
If the inter arrival time is nonlattice and $\mathbb{E}[X^2] < \infty$, we have 
\begin{flalign*}
\lim_{t \rightarrow \infty} \left(m(t)-\frac{t}{\mu}\right) = \frac{\mathbb{E}[X^2]}{2\mu^2}-1.
\end{flalign*} 
\begin{proof}
This follows since $\mu (m(t)+1) = t + \mathbb{E}[Y(t)].$
\end{proof}

\end{prop}












\end{document}